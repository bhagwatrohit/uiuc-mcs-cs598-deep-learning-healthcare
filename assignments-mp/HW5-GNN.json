{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd9cbbb124ce54a1b4ecccd8e53d4c73",
     "grade": false,
     "grade_id": "cell-52506fc51faeb1a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# HW5 MPNN\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this question, we will try the Graph Neural Network (GNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32e72084469253ba7b428e2d0bd46613",
     "grade": false,
     "grade_id": "cell-dcd6c662fba70926",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T07:28:52.264736Z",
     "start_time": "2020-11-14T07:28:48.401775Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c90b41cb586816e3e89070cfe4d438d7",
     "grade": false,
     "grade_id": "cell-4fe346254a16fed8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T07:28:52.271638Z",
     "start_time": "2020-11-14T07:28:52.266855Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3eac88e6509802d55378549c8c90a990",
     "grade": false,
     "grade_id": "cell-6004290bcf81c83a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b40d90faedd814f0d467dadddaa32b7",
     "grade": false,
     "grade_id": "cell-50652afef8679215",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../HW5-GNN-lib/data/\"\n",
    "\n",
    "assert os.path.isdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "212e434fd38be5ca223e82a1e1fddf5b",
     "grade": false,
     "grade_id": "cell-71f2f1fcbf0214c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42240c150bebeba71017189237a14608",
     "grade": false,
     "grade_id": "cell-f24c5a8a552afa64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will use [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/index.html), which is a geometric deep learning extension library for PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "075924f95ac573b3717e3f6730deeef3",
     "grade": false,
     "grade_id": "cell-af2084dbbc442f32",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1 Graph [20 points]\n",
    "\n",
    "First, let us learn the fundamental concepts of PyTorch Geometric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d6da1881c6d613c171dde68cb0c79809",
     "grade": false,
     "grade_id": "cell-562360d4d2419770",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A graph is used to model pairwise relations (edges) between objects (nodes).\n",
    "A single graph in PyTorch Geometric is described by an instance of `torch_geometric.data.Data`, which holds the following attributes by default:\n",
    "\n",
    "- `data.x`: Node feature matrix with shape `[num_nodes, num_node_features]`\n",
    "- `data.edge_index`: Graph connectivity in COO format with shape `[2, num_edges]` and type `torch.long`\n",
    "- `data.edge_attr`: Edge feature matrix with shape `[num_edges, num_edge_features]`\n",
    "- `data.y`: Target to train against (may have arbitrary shape), *e.g.*, node-level targets of shape `[num_nodes, *]` or graph-level targets of shape `[1, *]`\n",
    "- `data.pos`: Node position matrix with shape `[num_nodes, num_dimensions]`\n",
    "\n",
    "Note that none of these attributes is required.\n",
    "\n",
    "We show a simple example of an unweighted and undirected graph with three nodes and four edges. Each node contains exactly one feature:\n",
    "\n",
    "<img width=\"500\" src=\"img/graph-1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T07:28:57.601627Z",
     "start_time": "2020-11-14T07:28:52.273985Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a0b830f8cd2fe28be896901ac692098",
     "grade": false,
     "grade_id": "cell-a416f329b2ced06a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 4], x=[3, 1])\n",
      "num_nodes: 3\n",
      "num_edges: 4\n",
      "num_node_features: 1\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "print(data)\n",
    "print(\"num_nodes:\", data.num_nodes)\n",
    "print(\"num_edges:\", data.num_edges)\n",
    "print(\"num_node_features:\", data.num_node_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0857ae3b8841d38e77ff1571a28a06de",
     "grade": false,
     "grade_id": "cell-057189f6f4e8c507",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that although the graph has only two edges, we need to define four index tuples to account for both directions of a edge.\n",
    "\n",
    "Now, create a `torch_geometric.data.Data` instance for the following graph.\n",
    "\n",
    "<img width=\"250\" src=\"img/graph-2.png\">\n",
    "\n",
    "Assign the graph-level target $1$ to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T07:28:57.606290Z",
     "start_time": "2020-11-14T07:28:57.603650Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: create a `torch_geometric.data.Data` instance for the graph above. Set the graph-level target to 1.\n",
    "\"\"\"\n",
    "data = None\n",
    "\n",
    "# your code here\n",
    "#raise NotImplementedError\n",
    "edge_index = torch.tensor([[0, 0, 2, 1],\n",
    "                           [2, 1, 1, 3]], dtype=torch.long)\n",
    "data = Data( edge_index = edge_index, y=1, num_nodes = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T07:28:57.920035Z",
     "start_time": "2020-11-14T07:28:57.607839Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ddf66f45778a130b6e9b9410d8394a6",
     "grade": true,
     "grade_id": "cell-bbaa361d4cbc5a08",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "assert data.num_nodes == 4\n",
    "assert data.num_edges == 4\n",
    "assert data.y == 1\n",
    "assert data.num_node_features == 0\n",
    "assert data.num_edge_features == 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d4c76c2c3f53c868beb44dd27abad0f",
     "grade": false,
     "grade_id": "cell-43329f1737df8ae9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2 Dataset [20 points]\n",
    "\n",
    "For this question, we will use the [MUTAG dataset](http://networkrepository.com/Mutag.php). Each graph in the dataset represents a chemical compound and graph labels represent their mutagenic effect on a specific gram negative bacterium. The dataset includes 188 graphs. Graph nodes have 7 labels and each graph is labelled as belonging to 1 of 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T07:28:57.921782Z",
     "start_time": "2020-11-14T07:28:53.576Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fbcda45e62ab8697a61aeaef63f0ddcd",
     "grade": false,
     "grade_id": "cell-450a3e6b67209711",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 188\n",
      "num_classes: 2\n",
      "num_node_features: 7\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(root=DATA_PATH, name='MUTAG')\n",
    "print(\"len:\", len(dataset))\n",
    "print(\"num_classes:\", dataset.num_classes)\n",
    "print(\"num_node_features:\", dataset.num_node_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f356a17f9da949ed1344d3dcd8d671e3",
     "grade": false,
     "grade_id": "cell-e4938a04f56ed102",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let us take one graph as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T07:28:57.922832Z",
     "start_time": "2020-11-14T07:28:54.815Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3caae8ebfe4a5bfad6746c5fb4a6a012",
     "grade": false,
     "grade_id": "cell-c3829b149e33cc49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 17\n",
      "Number of edges: 38\n",
      "Number of features: 7\n",
      "Average node degree: 2.24\n",
      "Contains isolated nodes: False\n",
      "Contains self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Number of features: {data.num_node_features}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "971ac734d9f733cf3d0037cf535dd8f4",
     "grade": false,
     "grade_id": "cell-9d61d2bd530e86df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can see that the first graph in the dataset contains 17 nodes, each one having 7 features. There are 38/2 = 19 undirected edges and the graph is assigned to exactly one class. In addition, the data object is holding exactly one graph-level target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T07:28:57.923816Z",
     "start_time": "2020-11-14T07:28:56.367Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def graph_stat(dataset):\n",
    "    \"\"\"\n",
    "    TODO: calculate the statistics of the ENZYMES dataset.\n",
    "    \n",
    "    Outputs:\n",
    "        min_num_nodes: min number of nodes\n",
    "        max_num_nodes: max number of nodes\n",
    "        mean_num_nodes: average number of nodes\n",
    "        min_num_edges: min number of edges\n",
    "        max_num_edges: max number of edges\n",
    "        mean_num_edges: average number of edges\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    #raise NotImplementedError\n",
    "    number_of_nodes = np.array([], dtype=int)\n",
    "    number_of_edges = np.array([], dtype=int)\n",
    "    \n",
    "    for data in dataset:\n",
    "        number_of_nodes = np.append(number_of_nodes, data.num_nodes)\n",
    "        number_of_edges = np.append(number_of_edges, data.num_edges)\n",
    "    \n",
    "    min_num_nodes = np.min(number_of_nodes)\n",
    "    max_num_nodes = np.max(number_of_nodes)\n",
    "    mean_num_nodes = np.mean(np.asarray(number_of_nodes))\n",
    "    min_num_edges = np.min(number_of_edges)\n",
    "    max_num_edges = np.max(number_of_edges)\n",
    "    mean_num_edges = np.mean(number_of_edges)\n",
    "    \n",
    "    return min_num_nodes, max_num_nodes, mean_num_nodes, min_num_edges, max_num_edges, mean_num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T07:28:57.924872Z",
     "start_time": "2020-11-14T07:28:56.997Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a6bb153572ceb537ba709973e81c1ca",
     "grade": true,
     "grade_id": "cell-cdaa11793e76d9f6",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "assert np.allclose(graph_stat(dataset), (10, 28, 17.93, 20, 66, 39.58), atol=1e-2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "891b62474b2c4501680d4a13b12dc627",
     "grade": false,
     "grade_id": "cell-b140e35012a9155f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Neural networks are usually trained in a batch-wise fashion. PyTorch Geometric achieves parallelization over a mini-batch by creating sparse block diagonal adjacency matrices (defined by `edge_index`) and concatenating feature and target matrices in the node dimension. This composition allows differing number of nodes and edges over examples in one batch:\n",
    "\n",
    "$\\begin{split}\\mathbf{A} = \\begin{bmatrix} \\mathbf{A}_1 & & \\\\ & \\ddots & \\\\ & & \\mathbf{A}_n \\end{bmatrix}, \\qquad \\mathbf{X} = \\begin{bmatrix} \\mathbf{X}_1 \\\\ \\vdots \\\\ \\mathbf{X}_n \\end{bmatrix}, \\qquad \\mathbf{Y} = \\begin{bmatrix} \\mathbf{Y}_1 \\\\ \\vdots \\\\ \\mathbf{Y}_n \\end{bmatrix}\\end{split}$\n",
    "\n",
    "Luckily, PyTorch Geometric contains its own `torch_geometric.data.DataLoader`, which already takes care of this concatenation process. Let us learn about it in an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T07:28:58.355979Z",
     "start_time": "2020-11-14T07:28:58.343751Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee806eb6d502e92b74b5cb0e5d5feddd",
     "grade": false,
     "grade_id": "cell-c2ee216a9b969d90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[559], edge_attr=[1230, 4], edge_index=[2, 1230], x=[559, 7], y=[32])\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "loader_iter = iter(loader)\n",
    "batch = next(loader_iter)\n",
    "print(batch)\n",
    "print(batch.num_graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbdff428b701e33d93f4d60d789c1290",
     "grade": false,
     "grade_id": "cell-ef0aec44ade0b887",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "That is, each batch contains $32$ graphs whose nodes and edges are stacked into one matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "882b0a6379bfefdf3a5f10326a38af29",
     "grade": false,
     "grade_id": "cell-2df711bca4633384",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, let us create a 80/20 train/test split, and load them into the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T12:23:50.306823Z",
     "start_time": "2020-11-11T12:23:50.302651Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3c8f61b2651d859c0a7fcfe8b368eb2",
     "grade": false,
     "grade_id": "cell-f6ce36bdec40498e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train: 150\n",
      "len test: 38\n"
     ]
    }
   ],
   "source": [
    "# shuffle\n",
    "dataset = dataset.shuffle()\n",
    "# split\n",
    "split_idx = int(len(dataset) * 0.8)\n",
    "train_dataset = dataset[:split_idx]\n",
    "test_dataset = dataset[split_idx:]\n",
    "\n",
    "print(\"len train:\", len(train_dataset))\n",
    "print(\"len test:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T12:23:50.803631Z",
     "start_time": "2020-11-11T12:23:50.801058Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cdbd10cf2569ff43a1b981a8a1e2117",
     "grade": false,
     "grade_id": "cell-8b4723269937d4e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c1f6cf940d6e05b78bc057e1f9d5af3",
     "grade": false,
     "grade_id": "cell-59d9f0b1bd9306f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3 Graph Neural Network [40 points]\n",
    "\n",
    "After learning about the fundamental concepts in PyTorch Geometric, let us try implement our first graph neural network.\n",
    "\n",
    "We will use a simple Graph Convolution Network (GCN) to assign each enzyme to one of the 6 EC top-level classes.\n",
    "\n",
    "For a high-level explanation on GCN, have a look at its [blog](http://tkipf.github.io/graph-convolutional-networks/) post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da835b9f75c42c1b54d800a82dc6f8d5",
     "grade": false,
     "grade_id": "cell-652a92ed66e4289c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img width=\"500\" src=\"img/graph-3.png\">\n",
    "\n",
    "The GCN will have the following steps:\n",
    "\n",
    "- Embed each node by performing multiple rounds of message passing\n",
    "- Aggregate node embeddings into a unified graph embedding (readout layer)\n",
    "- Train a final classifier on the graph embedding\n",
    "\n",
    "\n",
    "There exists multiple readout layers in literature, but the most common one is to simply take the average of node embeddings:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{\\mathcal{G}} = \\frac{1}{|\\mathcal{V}|} \\sum_{v \\in \\mathcal{V}} \\mathcal{x}^{(L)}_v\n",
    "$$\n",
    "\n",
    "PyTorch Geometric provides this functionality via `torch_geometric.nn.global_mean_pool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T12:23:52.630823Z",
     "start_time": "2020-11-11T12:23:52.620890Z"
    },
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(7, 64)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): GCNConv(64, 64)\n",
       "  (relu2): ReLU()\n",
       "  (conv3): GCNConv(64, 64)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "            1. Define the first convolution layer using `GCNConv()`. Set `out_channels` to 64;\n",
    "            2. Define the first activation layer using `nn.ReLU()`;\n",
    "            3. Define the second convolution layer using `GCNConv()`. Set `out_channels` to 64;\n",
    "            4. Define the second activation layer using `nn.ReLU()`;\n",
    "            5. Define the third convolution layer using `GCNConv()`. Set `out_channels` to 64;\n",
    "            6. Define the dropout layer using `nn.Dropout()`;\n",
    "            7. Define the linear layer using `nn.Linear()`. Set `output_size` to 2.\n",
    "\n",
    "        Note that for MUTAG dataset, the number of node features is 7, and the number of classes is 2.\n",
    "\n",
    "        \"\"\"\n",
    "        #GCNConv(in_channels: int, out_channels: int, \n",
    "        # improved: bool = False, cached: bool = False, add_self_loops: bool = True, \n",
    "        # normalize: bool = True, bias: bool = True, **kwargs)[source]\n",
    "\n",
    "        \n",
    "        # your code here\n",
    "        # raise NotImplementedError\n",
    "        in_channels = data.num_node_features\n",
    "        self.conv1 = GCNConv(in_channels=in_channels, out_channels=64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = GCNConv(in_channels=64, out_channels=64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = GCNConv(in_channels=64, out_channels=64)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.linear = nn.Linear(in_features=64, out_features=2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "            1. Pass the data through the frst convolution layer;\n",
    "            2. Pass the data through the activation layer;\n",
    "            3. Pass the data through the second convolution layer;\n",
    "            4. Obtain the graph embeddings using the readout layer with `global_mean_pool()`;\n",
    "            5. Pass the graph embeddgins through the dropout layer;\n",
    "            6. Pass the graph embeddings through the linear layer.\n",
    "            \n",
    "        Arguments:\n",
    "            x: [num_nodes, 7], node features\n",
    "            edge_index: [2, num_edges], edges\n",
    "            batch: [num_nodes], batch assignment vector which maps each node to its \n",
    "                   respective graph in the batch\n",
    "\n",
    "        Outputs:\n",
    "            probs: probabilities of shape (batch_size, 2)\n",
    "        \"\"\"\n",
    "        \n",
    "        # your code here\n",
    "        # raise NotImplementedError\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "        \n",
    "GCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T12:23:57.286227Z",
     "start_time": "2020-11-11T12:23:57.279402Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "995ff4c4c48fbfe984ad005aef16779a",
     "grade": true,
     "grade_id": "cell-5e669e952726618a",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAUTOGRADER CELL. DO NOT MODIFY THIS.\\n'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T12:24:02.042229Z",
     "start_time": "2020-11-11T12:24:02.023964Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9146a6bdfd570355a344e0f4a1c20d5d",
     "grade": true,
     "grade_id": "cell-2759a5f7119635ed",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAUTOGRADER CELL. DO NOT MODIFY THIS.\\n'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6a99285568a25ad22e99bfa57d9498f",
     "grade": false,
     "grade_id": "cell-a90522f120575801",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 4 Training and Inferencing [20 points]\n",
    "\n",
    "Let us train our network for a few epochs to see how well it performs on the training as well as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T12:24:22.900724Z",
     "start_time": "2020-11-11T12:24:06.400308Z"
    },
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.6733, Test Acc: 0.6316\n",
      "Epoch: 002, Train Acc: 0.6733, Test Acc: 0.6316\n",
      "Epoch: 003, Train Acc: 0.6733, Test Acc: 0.6316\n",
      "Epoch: 004, Train Acc: 0.6733, Test Acc: 0.6316\n",
      "Epoch: 005, Train Acc: 0.6800, Test Acc: 0.6316\n",
      "Epoch: 006, Train Acc: 0.7400, Test Acc: 0.7368\n",
      "Epoch: 007, Train Acc: 0.7600, Test Acc: 0.7105\n",
      "Epoch: 008, Train Acc: 0.7200, Test Acc: 0.7632\n",
      "Epoch: 009, Train Acc: 0.7467, Test Acc: 0.7368\n",
      "Epoch: 010, Train Acc: 0.7533, Test Acc: 0.6842\n",
      "Epoch: 011, Train Acc: 0.7400, Test Acc: 0.7368\n",
      "Epoch: 012, Train Acc: 0.7267, Test Acc: 0.7632\n",
      "Epoch: 013, Train Acc: 0.7467, Test Acc: 0.7632\n",
      "Epoch: 014, Train Acc: 0.7267, Test Acc: 0.7632\n",
      "Epoch: 015, Train Acc: 0.7600, Test Acc: 0.7368\n",
      "Epoch: 016, Train Acc: 0.7400, Test Acc: 0.7368\n",
      "Epoch: 017, Train Acc: 0.7400, Test Acc: 0.7368\n",
      "Epoch: 018, Train Acc: 0.7600, Test Acc: 0.7105\n",
      "Epoch: 019, Train Acc: 0.7600, Test Acc: 0.7368\n",
      "Epoch: 020, Train Acc: 0.7600, Test Acc: 0.6842\n",
      "Epoch: 021, Train Acc: 0.7600, Test Acc: 0.7368\n",
      "Epoch: 022, Train Acc: 0.7600, Test Acc: 0.7105\n",
      "Epoch: 023, Train Acc: 0.7600, Test Acc: 0.7632\n",
      "Epoch: 024, Train Acc: 0.7400, Test Acc: 0.7368\n",
      "Epoch: 025, Train Acc: 0.7467, Test Acc: 0.6842\n",
      "Epoch: 026, Train Acc: 0.7467, Test Acc: 0.7368\n",
      "Epoch: 027, Train Acc: 0.7600, Test Acc: 0.7632\n",
      "Epoch: 028, Train Acc: 0.7533, Test Acc: 0.7105\n",
      "Epoch: 029, Train Acc: 0.7467, Test Acc: 0.7368\n",
      "Epoch: 030, Train Acc: 0.7400, Test Acc: 0.7368\n",
      "Epoch: 031, Train Acc: 0.7400, Test Acc: 0.7368\n",
      "Epoch: 032, Train Acc: 0.7400, Test Acc: 0.7105\n",
      "Epoch: 033, Train Acc: 0.7667, Test Acc: 0.7632\n",
      "Epoch: 034, Train Acc: 0.7467, Test Acc: 0.7368\n",
      "Epoch: 035, Train Acc: 0.7400, Test Acc: 0.7105\n",
      "Epoch: 036, Train Acc: 0.7533, Test Acc: 0.7368\n",
      "Epoch: 037, Train Acc: 0.7533, Test Acc: 0.7368\n",
      "Epoch: 038, Train Acc: 0.7533, Test Acc: 0.7368\n",
      "Epoch: 039, Train Acc: 0.7533, Test Acc: 0.7368\n",
      "Epoch: 040, Train Acc: 0.7600, Test Acc: 0.7368\n",
      "Epoch: 041, Train Acc: 0.7467, Test Acc: 0.7368\n",
      "Epoch: 042, Train Acc: 0.7533, Test Acc: 0.7368\n",
      "Epoch: 043, Train Acc: 0.7467, Test Acc: 0.7368\n",
      "Epoch: 044, Train Acc: 0.7600, Test Acc: 0.7632\n",
      "Epoch: 045, Train Acc: 0.7533, Test Acc: 0.7368\n",
      "Epoch: 046, Train Acc: 0.7600, Test Acc: 0.7632\n",
      "Epoch: 047, Train Acc: 0.7533, Test Acc: 0.7368\n",
      "Epoch: 048, Train Acc: 0.7600, Test Acc: 0.7632\n",
      "Epoch: 049, Train Acc: 0.7600, Test Acc: 0.7632\n",
      "Epoch: 050, Train Acc: 0.7533, Test Acc: 0.7368\n",
      "Epoch: 051, Train Acc: 0.7533, Test Acc: 0.7368\n",
      "Epoch: 052, Train Acc: 0.7600, Test Acc: 0.7632\n",
      "Epoch: 053, Train Acc: 0.7600, Test Acc: 0.7632\n",
      "Epoch: 054, Train Acc: 0.7600, Test Acc: 0.7368\n",
      "Epoch: 055, Train Acc: 0.7600, Test Acc: 0.7632\n",
      "Epoch: 056, Train Acc: 0.7600, Test Acc: 0.7368\n",
      "Epoch: 057, Train Acc: 0.7667, Test Acc: 0.6842\n",
      "Epoch: 058, Train Acc: 0.7800, Test Acc: 0.7632\n",
      "Epoch: 059, Train Acc: 0.7600, Test Acc: 0.7368\n",
      "Epoch: 060, Train Acc: 0.7600, Test Acc: 0.7105\n",
      "Epoch: 061, Train Acc: 0.7600, Test Acc: 0.7368\n",
      "Epoch: 062, Train Acc: 0.7533, Test Acc: 0.7368\n",
      "Epoch: 063, Train Acc: 0.7600, Test Acc: 0.7632\n",
      "Epoch: 064, Train Acc: 0.7600, Test Acc: 0.7368\n",
      "Epoch: 065, Train Acc: 0.7600, Test Acc: 0.6842\n",
      "Epoch: 066, Train Acc: 0.7600, Test Acc: 0.6842\n",
      "Epoch: 067, Train Acc: 0.7600, Test Acc: 0.7368\n",
      "Epoch: 068, Train Acc: 0.7600, Test Acc: 0.7368\n",
      "Epoch: 069, Train Acc: 0.7600, Test Acc: 0.7105\n",
      "Epoch: 070, Train Acc: 0.7667, Test Acc: 0.7368\n",
      "Epoch: 071, Train Acc: 0.7800, Test Acc: 0.7632\n",
      "Epoch: 072, Train Acc: 0.7667, Test Acc: 0.7105\n",
      "Epoch: 073, Train Acc: 0.7733, Test Acc: 0.6842\n",
      "Epoch: 074, Train Acc: 0.7733, Test Acc: 0.7368\n",
      "Epoch: 075, Train Acc: 0.7600, Test Acc: 0.6842\n",
      "Epoch: 076, Train Acc: 0.7667, Test Acc: 0.6842\n",
      "Epoch: 077, Train Acc: 0.7667, Test Acc: 0.7368\n",
      "Epoch: 078, Train Acc: 0.7800, Test Acc: 0.7368\n",
      "Epoch: 079, Train Acc: 0.7733, Test Acc: 0.6842\n",
      "Epoch: 080, Train Acc: 0.7800, Test Acc: 0.6842\n",
      "Epoch: 081, Train Acc: 0.7800, Test Acc: 0.6842\n",
      "Epoch: 082, Train Acc: 0.7867, Test Acc: 0.6842\n",
      "Epoch: 083, Train Acc: 0.7867, Test Acc: 0.6842\n",
      "Epoch: 084, Train Acc: 0.7800, Test Acc: 0.7105\n",
      "Epoch: 085, Train Acc: 0.7933, Test Acc: 0.6842\n",
      "Epoch: 086, Train Acc: 0.7867, Test Acc: 0.6842\n",
      "Epoch: 087, Train Acc: 0.7733, Test Acc: 0.7368\n",
      "Epoch: 088, Train Acc: 0.8000, Test Acc: 0.7368\n",
      "Epoch: 089, Train Acc: 0.7667, Test Acc: 0.6842\n",
      "Epoch: 090, Train Acc: 0.7800, Test Acc: 0.7368\n",
      "Epoch: 091, Train Acc: 0.7733, Test Acc: 0.6842\n",
      "Epoch: 092, Train Acc: 0.7933, Test Acc: 0.6842\n",
      "Epoch: 093, Train Acc: 0.7933, Test Acc: 0.7368\n",
      "Epoch: 094, Train Acc: 0.7933, Test Acc: 0.7368\n",
      "Epoch: 095, Train Acc: 0.7800, Test Acc: 0.7105\n",
      "Epoch: 096, Train Acc: 0.7933, Test Acc: 0.6842\n",
      "Epoch: 097, Train Acc: 0.7933, Test Acc: 0.7368\n",
      "Epoch: 098, Train Acc: 0.7867, Test Acc: 0.6842\n",
      "Epoch: 099, Train Acc: 0.8067, Test Acc: 0.7105\n",
      "Epoch: 100, Train Acc: 0.8067, Test Acc: 0.7368\n",
      "Epoch: 101, Train Acc: 0.8067, Test Acc: 0.7105\n",
      "Epoch: 102, Train Acc: 0.8067, Test Acc: 0.7368\n",
      "Epoch: 103, Train Acc: 0.7800, Test Acc: 0.7105\n",
      "Epoch: 104, Train Acc: 0.8000, Test Acc: 0.7368\n",
      "Epoch: 105, Train Acc: 0.7800, Test Acc: 0.7105\n",
      "Epoch: 106, Train Acc: 0.7933, Test Acc: 0.7368\n",
      "Epoch: 107, Train Acc: 0.7933, Test Acc: 0.7105\n",
      "Epoch: 108, Train Acc: 0.8133, Test Acc: 0.7368\n",
      "Epoch: 109, Train Acc: 0.8000, Test Acc: 0.7368\n",
      "Epoch: 110, Train Acc: 0.8000, Test Acc: 0.7368\n",
      "Epoch: 111, Train Acc: 0.7867, Test Acc: 0.7105\n",
      "Epoch: 112, Train Acc: 0.7933, Test Acc: 0.7368\n",
      "Epoch: 113, Train Acc: 0.7933, Test Acc: 0.6842\n",
      "Epoch: 114, Train Acc: 0.8067, Test Acc: 0.7105\n",
      "Epoch: 115, Train Acc: 0.8067, Test Acc: 0.7368\n",
      "Epoch: 116, Train Acc: 0.7867, Test Acc: 0.7368\n",
      "Epoch: 117, Train Acc: 0.8067, Test Acc: 0.7368\n",
      "Epoch: 118, Train Acc: 0.7933, Test Acc: 0.7105\n",
      "Epoch: 119, Train Acc: 0.7933, Test Acc: 0.7105\n",
      "Epoch: 120, Train Acc: 0.8067, Test Acc: 0.7368\n",
      "Epoch: 121, Train Acc: 0.8067, Test Acc: 0.7105\n",
      "Epoch: 122, Train Acc: 0.7933, Test Acc: 0.7368\n",
      "Epoch: 123, Train Acc: 0.8067, Test Acc: 0.7368\n",
      "Epoch: 124, Train Acc: 0.8000, Test Acc: 0.7105\n",
      "Epoch: 125, Train Acc: 0.8067, Test Acc: 0.7105\n",
      "Epoch: 126, Train Acc: 0.8333, Test Acc: 0.7632\n",
      "Epoch: 127, Train Acc: 0.8333, Test Acc: 0.7632\n",
      "Epoch: 128, Train Acc: 0.7933, Test Acc: 0.7368\n",
      "Epoch: 129, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 130, Train Acc: 0.8067, Test Acc: 0.7368\n",
      "Epoch: 131, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 132, Train Acc: 0.8067, Test Acc: 0.7632\n",
      "Epoch: 133, Train Acc: 0.8067, Test Acc: 0.7368\n",
      "Epoch: 134, Train Acc: 0.8067, Test Acc: 0.7895\n",
      "Epoch: 135, Train Acc: 0.7933, Test Acc: 0.7368\n",
      "Epoch: 136, Train Acc: 0.7933, Test Acc: 0.7368\n",
      "Epoch: 137, Train Acc: 0.8200, Test Acc: 0.7368\n",
      "Epoch: 138, Train Acc: 0.8133, Test Acc: 0.7632\n",
      "Epoch: 139, Train Acc: 0.7933, Test Acc: 0.7632\n",
      "Epoch: 140, Train Acc: 0.8267, Test Acc: 0.7895\n",
      "Epoch: 141, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 142, Train Acc: 0.8133, Test Acc: 0.7632\n",
      "Epoch: 143, Train Acc: 0.8067, Test Acc: 0.7895\n",
      "Epoch: 144, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 145, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 146, Train Acc: 0.8133, Test Acc: 0.7632\n",
      "Epoch: 147, Train Acc: 0.8067, Test Acc: 0.7895\n",
      "Epoch: 148, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 149, Train Acc: 0.8200, Test Acc: 0.7895\n",
      "Epoch: 150, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 151, Train Acc: 0.8133, Test Acc: 0.7632\n",
      "Epoch: 152, Train Acc: 0.8067, Test Acc: 0.7895\n",
      "Epoch: 153, Train Acc: 0.7800, Test Acc: 0.6579\n",
      "Epoch: 154, Train Acc: 0.7733, Test Acc: 0.7368\n",
      "Epoch: 155, Train Acc: 0.8133, Test Acc: 0.7632\n",
      "Epoch: 156, Train Acc: 0.8067, Test Acc: 0.7368\n",
      "Epoch: 157, Train Acc: 0.7933, Test Acc: 0.7632\n",
      "Epoch: 158, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 159, Train Acc: 0.8067, Test Acc: 0.7895\n",
      "Epoch: 160, Train Acc: 0.8333, Test Acc: 0.7632\n",
      "Epoch: 161, Train Acc: 0.8067, Test Acc: 0.7632\n",
      "Epoch: 162, Train Acc: 0.8000, Test Acc: 0.7632\n",
      "Epoch: 163, Train Acc: 0.8000, Test Acc: 0.7368\n",
      "Epoch: 164, Train Acc: 0.8133, Test Acc: 0.7632\n",
      "Epoch: 165, Train Acc: 0.8000, Test Acc: 0.7105\n",
      "Epoch: 166, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 167, Train Acc: 0.8133, Test Acc: 0.8158\n",
      "Epoch: 168, Train Acc: 0.8133, Test Acc: 0.7632\n",
      "Epoch: 169, Train Acc: 0.8133, Test Acc: 0.7632\n",
      "Epoch: 170, Train Acc: 0.8000, Test Acc: 0.7368\n",
      "Epoch: 171, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 172, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 173, Train Acc: 0.8067, Test Acc: 0.7895\n",
      "Epoch: 174, Train Acc: 0.8333, Test Acc: 0.7632\n",
      "Epoch: 175, Train Acc: 0.8200, Test Acc: 0.7895\n",
      "Epoch: 176, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 177, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 178, Train Acc: 0.8200, Test Acc: 0.8158\n",
      "Epoch: 179, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 180, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 181, Train Acc: 0.8267, Test Acc: 0.8158\n",
      "Epoch: 182, Train Acc: 0.8133, Test Acc: 0.7632\n",
      "Epoch: 183, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 184, Train Acc: 0.8067, Test Acc: 0.7895\n",
      "Epoch: 185, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 186, Train Acc: 0.8267, Test Acc: 0.8421\n",
      "Epoch: 187, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 188, Train Acc: 0.8333, Test Acc: 0.7632\n",
      "Epoch: 189, Train Acc: 0.8067, Test Acc: 0.7632\n",
      "Epoch: 190, Train Acc: 0.8067, Test Acc: 0.7368\n",
      "Epoch: 191, Train Acc: 0.8200, Test Acc: 0.8421\n",
      "Epoch: 192, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 193, Train Acc: 0.8333, Test Acc: 0.7895\n",
      "Epoch: 194, Train Acc: 0.8333, Test Acc: 0.8158\n",
      "Epoch: 195, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 196, Train Acc: 0.8267, Test Acc: 0.8158\n",
      "Epoch: 197, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 198, Train Acc: 0.8133, Test Acc: 0.8421\n",
      "Epoch: 199, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 200, Train Acc: 0.8133, Test Acc: 0.8158\n"
     ]
    }
   ],
   "source": [
    "gcn = GCN()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(gcn.parameters(), lr=0.01)\n",
    "# loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(train_loader):\n",
    "    gcn.train()\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        \"\"\"\n",
    "        TODO: train the model for one epoch.\n",
    "        \n",
    "        Note that you can acess the batch data using `data.x`, `data.edge_index`, `data.batch`, `data,y`.\n",
    "        \"\"\"\n",
    "        \n",
    "        # your code here\n",
    "        # raise NotImplementedError\n",
    "        train_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        out = gcn(data.x, data.edge_index, data.batch) \n",
    "        loss = criterion(out, data.y)    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "\n",
    "def test(loader):\n",
    "    gcn.eval()\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = gcn(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(200):\n",
    "    train(train_loader)\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch + 1:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T12:24:22.915971Z",
     "start_time": "2020-11-11T12:24:22.902692Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6d8e68acd8b72a4719554b964a50630",
     "grade": true,
     "grade_id": "cell-963e477404fcd251",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "test_acc = test(test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "illinois_payload": {
   "b64z": "",
   "nb_path": "release/HW5-GNN/HW5-GNN.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (Threads: 2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "852px",
    "left": "493px",
    "top": "256px",
    "width": "358.375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
