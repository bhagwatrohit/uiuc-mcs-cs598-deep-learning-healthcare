{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a302fa9f1a1ad9351180d1be7b81e56",
     "grade": false,
     "grade_id": "cell-52506fc51faeb1a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# HW4 RETAIN\n",
    "\n",
    "## Overview\n",
    "\n",
    "Previously, you tried mortality predictioin with classical machine learning models, neural network (NN), and recurrent neural network (RNN). \n",
    "\n",
    "In this question, you will try a different approach. You will implement RETAIN, a RNN model with attention mechanism,  proposed by Choi et al. in the paper [RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism](https://arxiv.org/abs/1608.05745)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32e72084469253ba7b428e2d0bd46613",
     "grade": false,
     "grade_id": "cell-dcd6c662fba70926",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T03:59:41.313420Z",
     "start_time": "2020-11-20T03:59:41.015941Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "478f107350e8fe54bd6fc439ffe45f4a",
     "grade": false,
     "grade_id": "cell-4fe346254a16fed8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T03:59:41.505980Z",
     "start_time": "2020-11-20T03:59:41.501919Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3eac88e6509802d55378549c8c90a990",
     "grade": false,
     "grade_id": "cell-6004290bcf81c83a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d339bf10f04be86877324b8c0d055edf",
     "grade": false,
     "grade_id": "cell-608226d648dacf7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../HW4-RETAIN-lib/data/\"\n",
    "\n",
    "assert os.path.isdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "212e434fd38be5ca223e82a1e1fddf5b",
     "grade": false,
     "grade_id": "cell-71f2f1fcbf0214c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47a47948f16e8882e8d5ea49560e6eca",
     "grade": false,
     "grade_id": "cell-f24c5a8a552afa64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "We will perform mortality prediction using the diagnosis codes. The dataset we are using is from the *ADMISSIONS*, *DIAGNOSES_ICD*, and *PATIENTS* tables of [MIMIC-III](https://mimic.physionet.org/gettingstarted/access/) dataset. Here is an overview of the three tables.\n",
    "\n",
    "- *ADMISSIONS*: Define a patient’s hospital admission, HADM_ID.\n",
    "- *DIAGNOSES_ICD*: Contains ICD diagnoses for patients, most notably ICD-9 diagnoses.\n",
    "- *PATIENTS*: Defines each SUBJECT_ID in the database, i.e. defines a single patient.\n",
    "\n",
    "The data has been preprocessed for you. Let us load them and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:57:42.689484Z",
     "start_time": "2020-11-01T13:57:42.641440Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6cc314ecc37883f46980b60a0e6c223d",
     "grade": false,
     "grade_id": "cell-0d031c45ba4a787e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pids = pickle.load(open(f'{DATA_PATH}/mimic3.pids', 'rb'))\n",
    "dates = pickle.load(open(f'{DATA_PATH}/mimic3.dates', 'rb'))\n",
    "morts = pickle.load(open(f'{DATA_PATH}/mimic3.morts', 'rb'))\n",
    "seqs = pickle.load(open(f'{DATA_PATH}/mimic3.3digitICD9.seqs', 'rb'))\n",
    "types = pickle.load(open(f'{DATA_PATH}/mimic3.3digitICD9.types', 'rb'))\n",
    "rtypes = dict([(v,k) for k,v in types.items()])\n",
    "\n",
    "assert len(pids) == len(dates) == len(morts) == len(seqs) == 7537\n",
    "assert len(types) == 942"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b9652dbed3e5c26e3ba645edb738cab",
     "grade": false,
     "grade_id": "cell-66a0abe057d9ca85",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "where\n",
    "\n",
    "- `pids`: contains the patient ids\n",
    "- `dates`: contains a list of admission dates for each patient\n",
    "- `morts`: contains the mortality information (0: alive, 1: dead)\n",
    "- `seqs`: contains a list of ICD-9 labels for admission of each patient\n",
    "- `types`: contains the map from 3-digit ICD-9 codes to ICD-9 labels\n",
    "- `rtypes`: contains the map from ICD-9 labels to 3-digit ICD-9 codes\n",
    "\n",
    "Let us take a patient as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:57:44.073360Z",
     "start_time": "2020-11-01T13:57:44.068727Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2526968dc549b79ae0dbb8aeecb502c4",
     "grade": false,
     "grade_id": "cell-ae331190a6d48106",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: 362\n",
      "Mortality: 0\n",
      "# of admissions: 2\n",
      "\t0-th admission date: 2112-07-10 02:31:00\n",
      "\t0-th admission diagnosis labels: [77, 3, 78, 79, 45, 15, 80, 81]\n",
      "\t0-th admission diagnosis codes: ['D_E885', 'D_401', 'D_397', 'D_396', 'D_599', 'D_427', 'D_253', 'D_852']\n",
      "\t1-th admission date: 2112-07-28 17:08:00\n",
      "\t1-th admission diagnosis labels: [77, 3, 5, 15, 17, 81]\n",
      "\t1-th admission diagnosis codes: ['D_E885', 'D_401', 'D_424', 'D_427', 'D_428', 'D_852']\n"
     ]
    }
   ],
   "source": [
    "# take the 5-th patient as an example\n",
    "\n",
    "print(\"Patient ID:\", pids[5])\n",
    "print(\"Mortality:\", morts[5])\n",
    "print(\"# of admissions:\", len(dates[5]))\n",
    "for visit in range(len(dates[5])):\n",
    "    print(f\"\\t{visit}-th admission date:\", dates[5][visit])\n",
    "    print(f\"\\t{visit}-th admission diagnosis labels:\", seqs[5][visit])\n",
    "    print(f\"\\t{visit}-th admission diagnosis codes:\", [rtypes[label] for label in seqs[5][visit]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "30607c6514b0b92e6a0d2877f832f9fe",
     "grade": false,
     "grade_id": "cell-945119717fb61cc7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that `seqs` is a list of list of list. That is, `seqs[i][j][k]` gives you the k-th diagnosis codes for the j-th visit for the i-th patient.\n",
    "\n",
    "And you can look up the meaning of the ICD-9 code online. For example, `D_427` represetns *cardiac dysrhythmias*.\n",
    "\n",
    "Further, let see number of mortalities cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:57:45.297255Z",
     "start_time": "2020-11-01T13:57:45.294471Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59f3528139dcbaefb15fcd8ee775253d",
     "grade": false,
     "grade_id": "cell-e6d339169f140694",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of mortalities: 2825\n",
      "ratio of mortalities: 0.37\n"
     ]
    }
   ],
   "source": [
    "print(\"number of mortalities:\", sum(morts))\n",
    "print(\"ratio of mortalities: %.2f\" % (sum(morts) / len(morts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b073b90483c506cae5f37e2db3af7681",
     "grade": false,
     "grade_id": "cell-308c526175fdb62e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1 Build the dataset [25 points]\n",
    "\n",
    "### 1.1 CustomDataset [5 points]\n",
    "\n",
    "First, let us implement a custom dataset using PyTorch class `Dataset`, which will characterize the key features of the dataset we want to generate.\n",
    "\n",
    "We will use the sequences of diagnosis codes `seqs` as input and mortality `morts` as output.\n",
    "\n",
    "Note that we can still use `TorchText` as it provides a generic way to deal with sequential data. But we will implement the `Dataset` from scratch this time so that you can have more hands-on experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:57:46.751506Z",
     "start_time": "2020-11-01T13:57:46.747553Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, seqs, morts):\n",
    "        self.x = seqs\n",
    "        self.y = morts\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        TODO: Return the number of samples (i.e. patients).\n",
    "        \"\"\"\n",
    "        \n",
    "        # your code here\n",
    "        # raise NotImplementedError\n",
    "        return len(self.x)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        \"\"\"\n",
    "        TODO: Generates one sample of data.\n",
    "        \n",
    "        Note that you DO NOT need to covert them to tensor as we will do this later.\n",
    "        \"\"\"\n",
    "        \n",
    "        # your code here\n",
    "        # raise NotImplementedError\n",
    "        return (self.x[index], self.y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:57:47.364437Z",
     "start_time": "2020-11-01T13:57:47.325271Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e90593734d8c67ff12ce4acc150cdb6",
     "grade": true,
     "grade_id": "cell-cc0baa6c9dadef8c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "dataset = CustomDataset(seqs, morts)\n",
    "assert len(dataset) == 7537\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7537\n",
      "([[12, 13, 6, 14, 15, 16, 17, 18], [12, 19, 6, 20, 15, 21, 17]], 0)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.__len__())\n",
    "print(dataset.__getitem__(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3aba7047609b50fb3c1b3d8d1b54661",
     "grade": false,
     "grade_id": "cell-de0d816943d88377",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 Collate Function [15 points]\n",
    "\n",
    "As you note that, we do not convert the data to tensor in the built `CustomDataset`. Instead, we will do this using a collate function `collate_fn()`. \n",
    "\n",
    "This collate function `collate_fn()` will be called by `DataLoader` after fetching a list of samples using the indices from `CustomDataset` to collate the list of samples into batches.\n",
    "\n",
    "For example, assume the `DataLoader` gets a list of two samples.\n",
    "\n",
    "```\n",
    "[ [ [0, 1, 2], [8, 0] ], \n",
    "  [ [12, 13, 6, 7], [12], [23, 11] ] ]\n",
    "```\n",
    "\n",
    "where the first sample has two visits `[0, 1, 2]` and `[8, 0]` and the second sample has three visits `[12, 13, 6, 7]`, `[12]`, and `[23, 11]`.\n",
    "\n",
    "The collate function `collate_fn()` is supposed to pad them into the same shape (3, 4), where 3 is the maximum number of visits and 4 is the maximum number of diagnosis codes.\n",
    "\n",
    "``` \n",
    "[ [ [0, 1, 2, *0*], [8, 0, *0*, *0*], [*0*, *0*, *0*, *0*]  ], \n",
    "  [ [12, 13, 6, 7], [12, *0*, *0*, *0*], [23, 11, *0*, *0*] ] ]\n",
    "```\n",
    "\n",
    "Further, the padding information will be stored in a mask with the same shape, where 1 indicates that the diagnosis code at this position is from the original input, and 0 indicates that the diagnosis code at this position is the padded value.\n",
    "\n",
    "```\n",
    "[ [ [1, 1, 1, 0], [1, 1, 0, 0], [0, 0, 0, 0] ], \n",
    "  [ [1, 1, 1, 1], [1, 0, 0, 0], [1, 1, 0, 0] ] ]\n",
    "```\n",
    "\n",
    "Lastly, we will have another diagnosis sequence in reversed time. This will be used in the RETAIN model. Note that we only flip the true visits.\n",
    "\n",
    "``` \n",
    "[ [ [8, 0, *0*, *0*], [0, 1, 2, *0*], [*0*, *0*, *0*, *0*]  ], \n",
    "  [ [23, 11, *0*, *0*], [12, *0*, *0*, *0*], [12, 13, 6, 7] ] ]\n",
    "```\n",
    "\n",
    "And a reversed mask as well.\n",
    "\n",
    "```\n",
    "[ [ [1, 1, 0, 0], [1, 1, 1, 0], [0, 0, 0, 0] ], \n",
    "  [ [1, 1, 0, 0], [1, 0, 0, 0], [1, 1, 1, 1], ] ]\n",
    "```\n",
    "\n",
    "We need to pad the sequences into the same length so that we can do batch training on GPU. And we also need this mask so that when training, we can ignored the padded value as they actually do not contain any information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:57:48.461122Z",
     "start_time": "2020-11-01T13:57:48.456083Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    Collate the the list of samples into batches. For each patient, you need to pad the diagnosis\n",
    "    sequences to the sample shape (max # visits, max # diagnosis codes). The padding infomation\n",
    "    is stored in `mask`.\n",
    "    \n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "        \n",
    "    Outputs:\n",
    "        x: a tensor of shape (# patiens, max # visits, max # diagnosis codes) of type torch.long\n",
    "        masks: a tensor of shape (# patiens, max # visits, max # diagnosis codes) of type torch.bool\n",
    "        rev_x: same as x but in reversed time.\n",
    "        rev_masks: same as mask but in reversed time.\n",
    "        y: a tensor of shape (# patiens) of type torch.float\n",
    "        \n",
    "    Note that you can obtains the list of diagnosis codes and the list of mortality labels\n",
    "        using: `sequences, labels = zip(*data)`\n",
    "    \"\"\"\n",
    "\n",
    "    sequences, labels = zip(*data)\n",
    "\n",
    "    y = torch.tensor(labels, dtype=torch.float)\n",
    "    \n",
    "    num_patients = len(sequences)\n",
    "    num_visits = [len(patient) for patient in sequences]\n",
    "    num_codes = [len(visit) for patient in sequences for visit in patient]\n",
    "\n",
    "    max_num_visits = max(num_visits)\n",
    "    max_num_codes = max(num_codes)\n",
    "    \n",
    "    x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
    "    rev_x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
    "    masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "    rev_masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "    for i_patient, patient in enumerate(sequences):\n",
    "        for j_visit, visit in enumerate(patient):\n",
    "            l = len(visit)\n",
    "            x[i_patient, j_visit, :l] = torch.tensor(visit, dtype=torch.long)\n",
    "            masks[i_patient, j_visit, :l].fill_(1)\n",
    "            \"\"\"\n",
    "            TODO: update rev_x and rev_masks. \n",
    "            \"\"\"\n",
    "            # your code here\n",
    "            # raise NotImplementedError\n",
    "            v = len(patient)\n",
    "            rev_x[i_patient, v-j_visit-1, :l] = torch.tensor(visit, dtype=torch.long)\n",
    "            rev_masks[i_patient, v-j_visit-1, :l].fill_(1)            \n",
    "    \n",
    "    return x, masks, rev_x, rev_masks, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:57:49.185824Z",
     "start_time": "2020-11-01T13:57:49.175784Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9cdb5758b5027bf4808aa6e3d5cc443",
     "grade": true,
     "grade_id": "cell-4b3472bbf5973793",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=10, collate_fn=collate_fn)\n",
    "loader_iter = iter(loader)\n",
    "x, masks, rev_x, rev_masks, y = next(loader_iter)\n",
    "\n",
    "assert x.dtype == rev_x.dtype == torch.long\n",
    "assert y.dtype == torch.float\n",
    "assert masks.dtype == rev_masks.dtype == torch.bool\n",
    "\n",
    "assert x.shape == rev_x.shape == masks.shape == rev_masks.shape == (10, 5, 21)\n",
    "assert y.shape == (10,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf11addba53d9041094d45051435cb7e",
     "grade": false,
     "grade_id": "cell-125312ce2d90406a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we have `CustomDataset` and `collate_fn()`. Let us split the dataset into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:57:50.270209Z",
     "start_time": "2020-11-01T13:57:50.266760Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc4a76fda00ecaef5a2e8857a49fb5f2",
     "grade": false,
     "grade_id": "cell-7f2e734b97c94232",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 6029\n",
      "Length of val dataset: 1508\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "split = int(len(dataset)*0.8)\n",
    "\n",
    "lengths = [split, len(dataset) - split]\n",
    "train_dataset, val_dataset = random_split(dataset, lengths)\n",
    "\n",
    "print(\"Length of train dataset:\", len(train_dataset))\n",
    "print(\"Length of val dataset:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de98a7101e7388850706de0e357437ad",
     "grade": false,
     "grade_id": "cell-c9732f7be72cb6e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3 DataLoader [5 points]\n",
    "\n",
    "Now, we can load the dataset into the data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:57:51.348998Z",
     "start_time": "2020-11-01T13:57:51.346288Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_data(train_dataset, val_dataset, collate_fn):\n",
    "    \n",
    "    '''\n",
    "    TODO: Implement this function to return the data loader for  train and validation dataset. \n",
    "    Set batchsize to 32. Set `shuffle=True` only for train dataloader.\n",
    "    \n",
    "    Arguments:\n",
    "        train dataset: train dataset of type `CustomDataset`\n",
    "        val dataset: validation dataset of type `CustomDataset`\n",
    "        collate_fn: collate function\n",
    "        \n",
    "    Outputs:\n",
    "        train_loader, val_loader: train and validation dataloaders\n",
    "    \n",
    "    Note that you need to pass the collate function to the data loader `collate_fn()`.\n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    # raise NotImplementedError\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:57:51.870013Z",
     "start_time": "2020-11-01T13:57:51.867646Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df70156c04ac389188618c83cade9be0",
     "grade": true,
     "grade_id": "cell-0c30a49563819f13",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "train_loader, val_loader = load_data(train_dataset, val_dataset, collate_fn)\n",
    "assert len(train_loader) == 189, 'number of training batches is wrong'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ebdf97f64fe487cdf8bd11311b79c075",
     "grade": false,
     "grade_id": "cell-a2fa0595b385b366",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2 RETAIN [60 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e29cad2ba2fdad004bd836333f02a12",
     "grade": false,
     "grade_id": "cell-482be961094244c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "RETAIN is essentially a RNN model with attention mechanism.\n",
    " \n",
    "The idea of attention is quite simple: it boils down to weighted averaging. Let us consider machine translation in class as an example. When generating a translation of a source text, we first pass the source text through an encoder (an LSTM or an equivalent model) to obtain a sequence of encoder hidden states $\\boldsymbol{h}_1, \\dots, \\boldsymbol{h}_T$. Then, at each step of generating a translation (decoding), we selectively attend to these encoder hidden states, that is, we construct a context vector $\\boldsymbol{c}_i$ that is a weighted average of encoder hidden states.\n",
    "\n",
    "$$\\boldsymbol{c}_i = \\underset{j}{\\Sigma} a_{ij}\\boldsymbol{h}_j$$\n",
    "\n",
    "We choose the weights $a_{ij}$ based both on encoder hidden states $\\boldsymbol{h}_1, \\dots, \\boldsymbol{h}_T$ and decoder hidden states $\\boldsymbol{s}_1, \\dots, \\boldsymbol{s}_T$ and normalize them so that they encode a categorical probability distribution $p(\\boldsymbol{h}_j | \\boldsymbol{s}_i)$.\n",
    "\n",
    "$$\\boldsymbol{a}_{i} = \\text{Softmax}\\left( a(\\boldsymbol{s}_i, \\boldsymbol{h}_j) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3949fe7f13ff12bcb4b80f0b51a83f10",
     "grade": false,
     "grade_id": "cell-7eb18a6f4e5350fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "RETAIN has two different attention mechanisms. \n",
    "- One is to help figure out what are the important visits. This attention $\\alpha_i$, which is scalar for the i-th visit, tells you the importance of the i-th visit.\n",
    "- Then we have another similar attention mechanism. But in this case, this attention ways $\\mathbf{\\beta}_i$ is a vector. That gives us a more detailed view of underlying cause of the input. That is, which are the important features within a visit.\n",
    "\n",
    "<img src=./img/retain-1.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T08:43:41.745655Z",
     "start_time": "2020-10-22T08:43:41.742778Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "946228c26560eb29c953e4c405535a87",
     "grade": false,
     "grade_id": "cell-f982ebdee9832892",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Unfolded view of RETAIN’s architecture: Given input sequence $\\mathbf{x}_1 , . . . , \\mathbf{x}_i$, we predict the label $\\mathbf{y}_i$. \n",
    "- Step 1: Embedding, \n",
    "- Step 2: generating $\\alpha$ values using RNN-$\\alpha$, \n",
    "- Step 3: generating $\\mathbf{\\beta}$ values using RNN-$\\beta$, \n",
    "- Step 4: Generating the context vector using attention and representation vectors, \n",
    "- Step 5: Making prediction. \n",
    "\n",
    "Note that in Steps 2 and 3 we use RNN in the reversed time.\n",
    "\n",
    "<img src=./img/retain-2.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce6fa086dbb68cd03fac0325fa85ea44",
     "grade": false,
     "grade_id": "cell-ba7e37a83e467960",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=./img/retain-3.png>\n",
    "\n",
    "Let us first implement RETAIN step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "702eb0c75ff4c84fe0da99b945ce7bd0",
     "grade": false,
     "grade_id": "cell-be223e923ff844ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1 Step 2: AlphaAttention [15 points]\n",
    "\n",
    "Implement the alpha attention in the second equation of step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T04:03:45.281471Z",
     "start_time": "2020-11-20T04:03:45.278264Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class AlphaAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Define the linear layer `self.a_att` for alpha-attention using `nn.Linear()`;\n",
    "        \n",
    "        Arguments:\n",
    "            hidden_dim: the hidden dimension\n",
    "        \"\"\"\n",
    "        \n",
    "        self.a_att = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, g):\n",
    "        \"\"\"\n",
    "        TODO: Implement the alpha attention.\n",
    "        \n",
    "        Arguments:\n",
    "            g: the output tensor from RNN-alpha of shape (batch_size, seq_length, hidden_dim) \n",
    "        \n",
    "        Outputs:\n",
    "            alpha: the corresponding attention weights of shape (batch_size, seq_length, 1)\n",
    "            \n",
    "        HINT: consider `torch.softmax`\n",
    "        \"\"\"\n",
    "        \n",
    "        # your code here\n",
    "        # raise NotImplementedError\n",
    "        alpha = self.a_att(g)\n",
    "        alpha = torch.softmax(alpha, 1)\n",
    "        \n",
    "        return alpha\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T04:03:45.625554Z",
     "start_time": "2020-11-20T04:03:45.619475Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0190f3d3e4167e4fa61519237b21a65",
     "grade": true,
     "grade_id": "cell-6ef630263469161e",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAUTOGRADER CELL. DO NOT MODIFY THIS.\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc8236b5eb3bd8434a59c3de15d36db8",
     "grade": false,
     "grade_id": "cell-d09c4bc0d5bf0e78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2 Step 3: BetaAttention [15 points]\n",
    "\n",
    "Implement the beta attention in the second equation of step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T04:03:46.033856Z",
     "start_time": "2020-11-20T04:03:46.030051Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class BetaAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Define the linear layer `self.b_att` for beta-attention using `nn.Linear()`;\n",
    "        \n",
    "        Arguments:\n",
    "            hidden_dim: the hidden dimension\n",
    "        \"\"\"\n",
    "        \n",
    "        self.b_att = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "\n",
    "    def forward(self, h):\n",
    "        \"\"\"\n",
    "        TODO: Implement the beta attention.\n",
    "        \n",
    "        Arguments:\n",
    "            h: the output tensor from RNN-beta of shape (batch_size, seq_length, hidden_dim) \n",
    "        \n",
    "        Outputs:\n",
    "            beta: the corresponding attention weights of shape (batch_size, seq_length, hidden_dim)\n",
    "            \n",
    "        HINT: consider `torch.tanh`\n",
    "        \"\"\"\n",
    "        \n",
    "        # your code here\n",
    "        # raise NotImplementedError\n",
    "        beta = self.b_att(h)\n",
    "        beta = torch.tanh(beta)\n",
    "        \n",
    "        return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T04:03:46.399639Z",
     "start_time": "2020-11-20T04:03:46.392931Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "530ab7387f49f5b95b7f0483489940aa",
     "grade": true,
     "grade_id": "cell-33b9b75995614f25",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAUTOGRADER CELL. DO NOT MODIFY THIS.\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f61f81966d7279ef00acc9db4d032b0e",
     "grade": false,
     "grade_id": "cell-92d8f1e9da0e999f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.3 Attention Sum [30 points]\n",
    "\n",
    "Implement the sum of attention in step 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T04:03:46.889200Z",
     "start_time": "2020-11-20T04:03:46.885995Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def attention_sum(alpha, beta, rev_v, rev_masks):\n",
    "    \"\"\"\n",
    "    TODO: mask select the hidden states for true visits (not padding visits) and then\n",
    "        sum the them up.\n",
    "\n",
    "    Arguments:\n",
    "        alpha: the alpha attention weights of shape (batch_size, seq_length, 1)\n",
    "        beta: the beta attention weights of shape (batch_size, seq_length, hidden_dim)\n",
    "        rev_v: the visit embeddings in reversed time of shape (batch_size, # visits, embedding_dim)\n",
    "        rev_masks: the padding masks in reversed time of shape (# visits, batch_size, # diagnosis codes)\n",
    "\n",
    "    Outputs:\n",
    "        c: the context vector of shape (batch_size, hidden_dim)\n",
    "        \n",
    "    NOTE: Do NOT use for loop.\n",
    "    \"\"\"\n",
    "    \n",
    "    # your code here\n",
    "    # raise NotImplementedError\n",
    "    # c = sum(alpha*beta dot v)\n",
    "    \n",
    "    mask = (torch.sum(rev_masks, -1) > 0).type(torch.float).unsqueeze(-1)\n",
    "    c = torch.sum(alpha*beta*rev_v*mask, dim=1)\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T04:03:47.404207Z",
     "start_time": "2020-11-20T04:03:47.396067Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ecb1402ca08327ac62814cb020bc36d",
     "grade": true,
     "grade_id": "cell-832260968193144c",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAUTOGRADER CELL. DO NOT MODIFY THIS.\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19039e2faa8bc3f96dd2452e5ad874eb",
     "grade": false,
     "grade_id": "cell-e743e3f53f6fa48d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.4 Build RETAIN\n",
    "\n",
    "Now, we can build the RETAIN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:57:54.499572Z",
     "start_time": "2020-11-01T13:57:54.496961Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "657bb0ca386783a293d79ed9ef2b2c2c",
     "grade": false,
     "grade_id": "cell-b6589b3ccf6f9a92",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sum_embeddings_with_mask(x, masks):\n",
    "    \"\"\"\n",
    "    Mask select the embeddings for true visits (not padding visits) and then sum the embeddings for each visit up.\n",
    "\n",
    "    Arguments:\n",
    "        x: the embeddings of diagnosis sequence of shape (batch_size, # visits, # diagnosis codes, embedding_dim)\n",
    "        masks: the padding masks of shape (batch_size, # visits, # diagnosis codes)\n",
    "\n",
    "    Outputs:\n",
    "        sum_embeddings: the sum of embeddings of shape (batch_size, # visits, embedding_dim)\n",
    "    \"\"\"\n",
    "    \n",
    "    x = x * masks.unsqueeze(-1)\n",
    "    x = torch.sum(x, dim = -2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T04:03:47.947861Z",
     "start_time": "2020-11-20T04:03:47.936508Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cd90fbe51c71622e32d6e7d53776d2f",
     "grade": false,
     "grade_id": "cell-02ad1b5432de58bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RETAIN(\n",
       "  (embedding): Embedding(942, 128)\n",
       "  (rnn_a): GRU(128, 128, batch_first=True)\n",
       "  (rnn_b): GRU(128, 128, batch_first=True)\n",
       "  (att_a): AlphaAttention(\n",
       "    (a_att): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (att_b): BetaAttention(\n",
       "    (b_att): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RETAIN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes):\n",
    "        super().__init__()\n",
    "        # Define the embedding layer using `nn.Embedding`. Set `embDimSize` to 128.\n",
    "        self.embedding = nn.Embedding(num_codes, 128)\n",
    "        # Define the RNN-alpha using `nn.GRU()`; Set `hidden_size` to 128. Set `batch_first` to True.\n",
    "        self.rnn_a = nn.GRU(128, 128, batch_first=True)\n",
    "        # Define the RNN-beta using `nn.GRU()`; Set `hidden_size` to 128. Set `batch_first` to True.\n",
    "        self.rnn_b = nn.GRU(128, 128, batch_first=True)\n",
    "        # Define the alpha-attention using `AlphaAttention()`;\n",
    "        self.att_a = AlphaAttention(128)\n",
    "        # Define the beta-attention using `BetaAttention()`;\n",
    "        self.att_b = BetaAttention(128)\n",
    "        # Define the linear layers using `nn.Linear()`;\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "        # Define the final activation layer using `nn.Sigmoid().\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x, masks, rev_x, rev_masks):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            rev_x: the diagnosis sequence in reversed time of shape (# visits, batch_size, # diagnosis codes)\n",
    "            rev_masks: the padding masks in reversed time of shape (# visits, batch_size, # diagnosis codes)\n",
    "\n",
    "        Outputs:\n",
    "            probs: probabilities of shape (batch_size)\n",
    "        \"\"\"\n",
    "        # 1. Pass the reversed sequence through the embedding layer;\n",
    "        rev_x = self.embedding(rev_x)\n",
    "        # 2. Sum the reversed embeddings for each diagnosis code up for a visit of a patient.\n",
    "        rev_x = sum_embeddings_with_mask(rev_x, rev_masks)\n",
    "        # 3. Pass the reversed embegginds through the RNN-alpha and RNN-beta layer separately;\n",
    "        g, _ = self.rnn_a(rev_x)\n",
    "        h, _ = self.rnn_b(rev_x)\n",
    "        # 4. Obtain the alpha and beta attentions using `AlphaAttention()` and `BetaAttention()`;\n",
    "        alpha = self.att_a(g)\n",
    "        beta = self.att_b(h)\n",
    "        # 5. Sum the attention up using `attention_sum()`;\n",
    "        c = attention_sum(alpha, beta, rev_x, rev_masks)\n",
    "        # 6. Pass the context vector through the linear and activation layers.\n",
    "        logits = self.fc(c)\n",
    "        probs = self.sigmoid(logits)\n",
    "        return probs.squeeze()\n",
    "    \n",
    "\n",
    "# load the model here\n",
    "retain = RETAIN(num_codes = len(types))\n",
    "retain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "assert retain.att_a.a_att.in_features == 128, \"alpha attention input features is wrong\"\n",
    "assert retain.att_a.a_att.out_features == 1, \"alpha attention output features is wrong\"\n",
    "assert retain.att_b.b_att.in_features == 128, \"beta attention input features is wrong\"\n",
    "assert retain.att_b.b_att.out_features == 128, \"beta attention output features is wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b6b25b6f5fc518cf445c125f22690bfe",
     "grade": false,
     "grade_id": "cell-873df7380d762445",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3 Training and Inferencing [15 points]\n",
    "\n",
    "Then, let us implement the `eval()` function first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T17:53:29.281635Z",
     "start_time": "2020-10-22T17:53:28.901898Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "\n",
    "def eval(model, val_loader):\n",
    "    \n",
    "    \"\"\"\n",
    "    Evaluate the model.\n",
    "    \n",
    "    Arguments:\n",
    "        model: the RNN model\n",
    "        val_loader: validation dataloader\n",
    "        \n",
    "    Outputs:\n",
    "        precision: overall precision score\n",
    "        recall: overall recall score\n",
    "        f1: overall f1 score\n",
    "        roc_auc: overall roc_auc score\n",
    "        \n",
    "    REFERENCE: checkout https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_score = torch.Tensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    model.eval()\n",
    "    for x, masks, rev_x, rev_masks, y in val_loader:\n",
    "        y_logit = model(x, masks, rev_x, rev_masks)\n",
    "        \"\"\"\n",
    "        TODO: obtain the predicted class (0, 1) by comparing y_logit against 0.5, \n",
    "              assign the predicted class to y_hat.\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        # raise NotImplementedError\n",
    "        y_hat = y_logit >= 0.5\n",
    "        \n",
    "        y_score = torch.cat((y_score,  y_logit.detach().to('cpu')), dim=0)\n",
    "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
    "    \n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "    return p, r, f, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a52b20a062ffbd7f40dd59951eeb4ff",
     "grade": false,
     "grade_id": "cell-9b3672b70944a8d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let us implement the `train()` function. Note that `train()` should call `eval()` at the end of each training epoch to see the results on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T17:53:55.590470Z",
     "start_time": "2020-10-22T17:53:29.669509Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, n_epochs):\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "    \n",
    "    Arguments:\n",
    "        model: the RNN model\n",
    "        train_loader: training dataloder\n",
    "        val_loader: validation dataloader\n",
    "        n_epochs: total number of epochs\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0\n",
    "        for x, masks, rev_x, rev_masks, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x, masks, rev_x, rev_masks)\n",
    "            \"\"\" \n",
    "            TODO: calculate the loss using `criterion`, save the output to loss.\n",
    "            \"\"\"\n",
    "            loss = None\n",
    "            # your code here\n",
    "            # raise NotImplementedError\n",
    "            loss = criterion(y_hat, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        p, r, f, roc_auc = eval(model, val_loader)\n",
    "        print('Epoch: {} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}, roc_auc: {:.2f}'\n",
    "              .format(epoch+1, p, r, f, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0641300bf647c8eecbb44e65fa8ef306",
     "grade": false,
     "grade_id": "cell-2f0785a5f7faf51f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 15, 128])\n",
      "torch.Size([32, 15, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128])\n",
      "---\n",
      "torch.Size([32, 19, 128])\n",
      "torch.Size([32, 19, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 17, 128])\n",
      "torch.Size([32, 17, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 21, 128])\n",
      "torch.Size([32, 21, 128])\n",
      "---\n",
      "torch.Size([32, 23, 128])\n",
      "torch.Size([32, 23, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 34, 128])\n",
      "torch.Size([32, 34, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 34, 128])\n",
      "torch.Size([32, 34, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 42, 128])\n",
      "torch.Size([32, 42, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 16, 128])\n",
      "torch.Size([32, 16, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 22, 128])\n",
      "torch.Size([32, 22, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 31, 128])\n",
      "torch.Size([32, 31, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 16, 128])\n",
      "torch.Size([32, 16, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([13, 5, 128])\n",
      "torch.Size([13, 5, 128])\n",
      "Epoch: 1 \t Training Loss: 0.600846\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 3, 128])\n",
      "torch.Size([32, 3, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 17, 128])\n",
      "torch.Size([32, 17, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 17, 128])\n",
      "torch.Size([32, 17, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([4, 3, 128])\n",
      "torch.Size([4, 3, 128])\n",
      "Epoch: 1 \t Validation p: 0.68, r:0.55, f: 0.61, roc_auc: 0.78\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 34, 128])\n",
      "torch.Size([32, 34, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 17, 128])\n",
      "torch.Size([32, 17, 128])\n",
      "---\n",
      "torch.Size([32, 19, 128])\n",
      "torch.Size([32, 19, 128])\n",
      "---\n",
      "torch.Size([32, 24, 128])\n",
      "torch.Size([32, 24, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 3, 128])\n",
      "torch.Size([32, 3, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 34, 128])\n",
      "torch.Size([32, 34, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 15, 128])\n",
      "torch.Size([32, 15, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 23, 128])\n",
      "torch.Size([32, 23, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 16, 128])\n",
      "torch.Size([32, 16, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 22, 128])\n",
      "torch.Size([32, 22, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 16, 128])\n",
      "torch.Size([32, 16, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 42, 128])\n",
      "torch.Size([32, 42, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 31, 128])\n",
      "torch.Size([32, 31, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 3, 128])\n",
      "torch.Size([32, 3, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 21, 128])\n",
      "torch.Size([32, 21, 128])\n",
      "---\n",
      "torch.Size([13, 5, 128])\n",
      "torch.Size([13, 5, 128])\n",
      "Epoch: 2 \t Training Loss: 0.443153\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 3, 128])\n",
      "torch.Size([32, 3, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 17, 128])\n",
      "torch.Size([32, 17, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 17, 128])\n",
      "torch.Size([32, 17, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([4, 3, 128])\n",
      "torch.Size([4, 3, 128])\n",
      "Epoch: 2 \t Validation p: 0.69, r:0.53, f: 0.60, roc_auc: 0.78\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 3, 128])\n",
      "torch.Size([32, 3, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 3, 128])\n",
      "torch.Size([32, 3, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 3, 128])\n",
      "torch.Size([32, 3, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 22, 128])\n",
      "torch.Size([32, 22, 128])\n",
      "---\n",
      "torch.Size([32, 42, 128])\n",
      "torch.Size([32, 42, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 23, 128])\n",
      "torch.Size([32, 23, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 34, 128])\n",
      "torch.Size([32, 34, 128])\n",
      "---\n",
      "torch.Size([32, 24, 128])\n",
      "torch.Size([32, 24, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 19, 128])\n",
      "torch.Size([32, 19, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 15, 128])\n",
      "torch.Size([32, 15, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 17, 128])\n",
      "torch.Size([32, 17, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 3, 128])\n",
      "torch.Size([32, 3, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 3, 128])\n",
      "torch.Size([32, 3, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 3, 128])\n",
      "torch.Size([32, 3, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 21, 128])\n",
      "torch.Size([32, 21, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 31, 128])\n",
      "torch.Size([32, 31, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 34, 128])\n",
      "torch.Size([32, 34, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 16, 128])\n",
      "torch.Size([32, 16, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 16, 128])\n",
      "torch.Size([32, 16, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([13, 4, 128])\n",
      "torch.Size([13, 4, 128])\n",
      "Epoch: 3 \t Training Loss: 0.280073\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 3, 128])\n",
      "torch.Size([32, 3, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 17, 128])\n",
      "torch.Size([32, 17, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 17, 128])\n",
      "torch.Size([32, 17, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([4, 3, 128])\n",
      "torch.Size([4, 3, 128])\n",
      "Epoch: 3 \t Validation p: 0.63, r:0.63, f: 0.63, roc_auc: 0.77\n",
      "---\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 31, 128])\n",
      "torch.Size([32, 31, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 17, 128])\n",
      "torch.Size([32, 17, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 23, 128])\n",
      "torch.Size([32, 23, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 16, 128])\n",
      "torch.Size([32, 16, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 3, 128])\n",
      "torch.Size([32, 3, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 22, 128])\n",
      "torch.Size([32, 22, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 21, 128])\n",
      "torch.Size([32, 21, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 34, 128])\n",
      "torch.Size([32, 34, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 19, 128])\n",
      "torch.Size([32, 19, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 42, 128])\n",
      "torch.Size([32, 42, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 15, 128])\n",
      "torch.Size([32, 15, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 24, 128])\n",
      "torch.Size([32, 24, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 3, 128])\n",
      "torch.Size([32, 3, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 16, 128])\n",
      "torch.Size([32, 16, 128])\n",
      "---\n",
      "torch.Size([32, 34, 128])\n",
      "torch.Size([32, 34, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([13, 6, 128])\n",
      "torch.Size([13, 6, 128])\n",
      "Epoch: 4 \t Training Loss: 0.137924\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 3, 128])\n",
      "torch.Size([32, 3, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 17, 128])\n",
      "torch.Size([32, 17, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 17, 128])\n",
      "torch.Size([32, 17, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([4, 3, 128])\n",
      "torch.Size([4, 3, 128])\n",
      "Epoch: 4 \t Validation p: 0.64, r:0.60, f: 0.62, roc_auc: 0.77\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 3, 128])\n",
      "torch.Size([32, 3, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 21, 128])\n",
      "torch.Size([32, 21, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 23, 128])\n",
      "torch.Size([32, 23, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 19, 128])\n",
      "torch.Size([32, 19, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 34, 128])\n",
      "torch.Size([32, 34, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 34, 128])\n",
      "torch.Size([32, 34, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 24, 128])\n",
      "torch.Size([32, 24, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 14, 128])\n",
      "torch.Size([32, 14, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 13, 128])\n",
      "torch.Size([32, 13, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 12, 128])\n",
      "torch.Size([32, 12, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 31, 128])\n",
      "torch.Size([32, 31, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 10, 128])\n",
      "torch.Size([32, 10, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 17, 128])\n",
      "torch.Size([32, 17, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 11, 128])\n",
      "torch.Size([32, 11, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 5, 128])\n",
      "torch.Size([32, 5, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 6, 128])\n",
      "torch.Size([32, 6, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n",
      "---\n",
      "torch.Size([32, 7, 128])\n",
      "torch.Size([32, 7, 128])\n",
      "---\n",
      "torch.Size([32, 16, 128])\n",
      "torch.Size([32, 16, 128])\n",
      "---\n",
      "torch.Size([32, 4, 128])\n",
      "torch.Size([32, 4, 128])\n",
      "---\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 128])\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "retain = RETAIN(num_codes = len(types))\n",
    "\n",
    "# load the loss function\n",
    "criterion = nn.BCELoss()\n",
    "# load the optimizer\n",
    "optimizer = torch.optim.Adam(retain.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 5\n",
    "train(retain, train_loader, val_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T04:03:48.734248Z",
     "start_time": "2020-11-20T04:03:48.724228Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f50bc5cbd79b0fdb46a95d7200bea12a",
     "grade": true,
     "grade_id": "cell-799d937773af6b46",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAUTOGRADER CELL. DO NOT MODIFY THIS.\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "illinois_payload": {
   "b64z": "",
   "nb_path": "release/HW4-RETAIN/HW4-RETAIN.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (Threads: 2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "852px",
    "left": "204px",
    "top": "110px",
    "width": "275.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
